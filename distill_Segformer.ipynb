{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSniQYqnwccX"
      },
      "source": [
        "# Дистилляция [SegFormer](https://huggingface.co/docs/transformers/model_doc/segformer)\n",
        "\n",
        "Будем дистилировать SegFormer для [задачи сегментации людей](https://www.kaggle.com/datasets/laurentmih/aisegmentcom-matting-human-datasets).\n",
        "\n",
        "Cам датасет [сегментации](https://drive.google.com/file/d/1YOEDzZvhLb2DS1Yn7p7MSs41ou3ZBXUq/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDR-qEWJwccb"
      },
      "source": [
        "### Установим библиотеки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPh_sgtzLQ-C"
      },
      "source": [
        "Установим рекомендованные библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwdgHUS1wccb",
        "outputId": "8cb47f01-96e6-467b-fae0-1143b7809bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers tensorboard pillow ipywidgets --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI5nu5olLQ-D"
      },
      "source": [
        "С библиотеками ниже возникают трудности по этому установим их зафиксировав версии\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6zdy-8VLQ-D",
        "outputId": "32649bb3-8a38-46e2-9c2b-909987ef35ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/468.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/110.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/134.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 install  datasets==v2.11.0 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_imJykhmLQ-D"
      },
      "source": [
        "Проверим наличие cuda драйвера в системе"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0-JJa1yLQ-D",
        "outputId": "9b7fe15c-7ca4-4a88-fd41-53cbc2ff4497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufM7IxecLQ-D"
      },
      "source": [
        "Установим торч в соответствии с версией драйвера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLb-IaaHLQ-D"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121/ --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zefNqxeLQ-D",
        "outputId": "7aaa53eb-a4ad-4a7f-a09e-3bc41fee2968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "2.5.1+cu124\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для колаба"
      ],
      "metadata": {
        "id": "V-00QmckLmMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CyhrVm6Ln-Q",
        "outputId": "0f14311c-9adc-4bc9-8b4d-abbbe04f48b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/distill/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBztWNQGcI9C",
        "outputId": "6526ed6f-5347-494a-8e71-90ac5913c1d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/distill\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjR-NSocLQ-D"
      },
      "source": [
        "### Работа с кодом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBfpng-GLQ-D"
      },
      "source": [
        "Не люблю смотреть на FutureWarnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPjPDrcdLQ-D"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjHHo_eLpYMa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import typing as tp\n",
        "import torch\n",
        "\n",
        "from copy import deepcopy\n",
        "from datasets import load_metric\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.tensorboard.writer import SummaryWriter\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# utils у нас появились при скачивании вспомогательного кода. При желании можно в них провалиться-поизучать\n",
        "from utils.data import init_dataloaders\n",
        "from utils.model import evaluate_model\n",
        "from utils.model import init_model_with_pretrain\n",
        "\n",
        "from torch import nn\n",
        "from transformers.models.segformer.modeling_segformer import SegformerLayer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXKfFbGmwccf"
      },
      "outputs": [],
      "source": [
        "teacher_path = 'runs/baseline_ckpt.pth'\n",
        "save_dir = 'runs/distillation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wXrcr--wccg"
      },
      "outputs": [],
      "source": [
        "tb_writer = SummaryWriter(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8GpVF2Dpkvs"
      },
      "outputs": [],
      "source": [
        "# маппинг названия классов и индексов\n",
        "id2label = {\n",
        "    0: \"background\",\n",
        "    1: \"human\",\n",
        "}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5H4Q1OK282K"
      },
      "source": [
        "Создадим лоадеры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DezHZJUSqIL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232224cb-fe06-46fa-b3e7-5aaa390de6ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_dataloader, valid_dataloader = init_dataloaders(\n",
        "    root_dir=\".\",\n",
        "    batch_size=16,\n",
        "    num_workers=8,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVu73sbywccj"
      },
      "source": [
        "Создадим модель учителя:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9cYusOhwcck",
        "outputId": "e2d1d9b3-5a7d-46f5-d5c8-e44d641e1455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_fuse.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "teacher_model = init_model_with_pretrain(label2id=label2id, id2label=id2label, pretrain_path=teacher_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruBhMcBYwccl"
      },
      "source": [
        "И сразу отвалидируем:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBFZ4REuwccl",
        "outputId": "a9d4a38e-9456-40c5-f7a3-60a7389f454c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean_iou: 0.9859686841316206\n",
            "Mean accuracy: 0.9929542821587765\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_iou': 0.9859686841316206,\n",
              " 'mean_accuracy': 0.9929542821587765,\n",
              " 'overall_accuracy': 0.9929354231878622,\n",
              " 'per_category_iou': array([0.98610262, 0.98583475]),\n",
              " 'per_category_accuracy': array([0.99129329, 0.99461527])}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "evaluate_model(teacher_model, valid_dataloader, id2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ju8cc7dwccm"
      },
      "source": [
        "## Делаем ученика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdTMgtH0wccm"
      },
      "source": [
        "Посмотрим, как выглядит модель учителя:\n",
        "\n",
        "Также можем воспользоваться сайтом https://netron.app/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9tyJ9kywccm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b9aa2a2-2fea-4c3b-c726-3afc985cf3fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SegformerForSemanticSegmentation(\n",
              "  (segformer): SegformerModel(\n",
              "    (encoder): SegformerEncoder(\n",
              "      (patch_embeddings): ModuleList(\n",
              "        (0): SegformerOverlapPatchEmbeddings(\n",
              "          (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
              "          (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): SegformerOverlapPatchEmbeddings(\n",
              "          (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): SegformerOverlapPatchEmbeddings(\n",
              "          (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): SegformerOverlapPatchEmbeddings(\n",
              "          (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (block): ModuleList(\n",
              "        (0): ModuleList(\n",
              "          (0): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
              "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
              "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): SegformerDropPath(p=0.014285714365541935)\n",
              "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ModuleList(\n",
              "          (0): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
              "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): SegformerDropPath(p=0.02857142873108387)\n",
              "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
              "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): SegformerDropPath(p=0.04285714402794838)\n",
              "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): ModuleList(\n",
              "          (0): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
              "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): SegformerDropPath(p=0.05714285746216774)\n",
              "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
              "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): SegformerDropPath(p=0.0714285746216774)\n",
              "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): ModuleList(\n",
              "          (0): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): SegformerDropPath(p=0.08571428805589676)\n",
              "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
              "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): ModuleList(\n",
              "        (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decode_head): SegformerDecodeHead(\n",
              "    (linear_c): ModuleList(\n",
              "      (0): SegformerMLP(\n",
              "        (proj): Linear(in_features=32, out_features=256, bias=True)\n",
              "      )\n",
              "      (1): SegformerMLP(\n",
              "        (proj): Linear(in_features=64, out_features=256, bias=True)\n",
              "      )\n",
              "      (2): SegformerMLP(\n",
              "        (proj): Linear(in_features=160, out_features=256, bias=True)\n",
              "      )\n",
              "      (3): SegformerMLP(\n",
              "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (activation): ReLU()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "teacher_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LufoOWWwccn"
      },
      "source": [
        "Нас интересует (block): он состоит из нескольких ModuleList. Нас интересуют первые четыре. Посмотрим на первый из них:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uil0gBQZwccn"
      },
      "source": [
        "```\n",
        "(0): ModuleList(\n",
        "          (0): SegformerLayer(\n",
        "            .... тут много понаписано\n",
        "          )\n",
        "          (1): SegformerLayer(\n",
        "            .... и тут тоже много всего\n",
        "        )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emRJ3fRvwcco"
      },
      "source": [
        "В каждом из четырёх ModuleList сидит по два `SegformerLayer`. Напишем функцию, которая оставит только один (последний) из них."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEXm29Aiwcco"
      },
      "outputs": [],
      "source": [
        "def create_small_network(model):\n",
        "    # \"\"\" Оставляет только по одному SegformerLayer в каждом ModuleList\"\"\"\n",
        "    modulelist_count = len(teacher_model.segformer.encoder.block)\n",
        "\n",
        "    for i in range(modulelist_count):\n",
        "        block = model.segformer.encoder.block[i]\n",
        "        model.segformer.encoder.block[i] = nn.ModuleList([block[-1]])\n",
        "    return model\n",
        "\n",
        "def n_params(model):\n",
        "    return sum(p.numel() for p in model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQJxdmRlwccp"
      },
      "outputs": [],
      "source": [
        "student_model = create_small_network(deepcopy(teacher_model))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_params(teacher_model) / n_params(student_model)"
      ],
      "metadata": {
        "id": "nIi-778ac7ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnF-e40bwccp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3e609b-e561-428d-e23d-03268d1a8125"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SegformerForSemanticSegmentation(\n",
              "  (segformer): SegformerModel(\n",
              "    (encoder): SegformerEncoder(\n",
              "      (patch_embeddings): ModuleList(\n",
              "        (0): SegformerOverlapPatchEmbeddings(\n",
              "          (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
              "          (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): SegformerOverlapPatchEmbeddings(\n",
              "          (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): SegformerOverlapPatchEmbeddings(\n",
              "          (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): SegformerOverlapPatchEmbeddings(\n",
              "          (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (block): ModuleList(\n",
              "        (0): ModuleList(\n",
              "          (0): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
              "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): SegformerDropPath(p=0.014285714365541935)\n",
              "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ModuleList(\n",
              "          (0): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
              "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): SegformerDropPath(p=0.04285714402794838)\n",
              "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): ModuleList(\n",
              "          (0): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
              "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): SegformerDropPath(p=0.0714285746216774)\n",
              "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): ModuleList(\n",
              "          (0): SegformerLayer(\n",
              "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (attention): SegformerAttention(\n",
              "              (self): SegformerEfficientSelfAttention(\n",
              "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "              (output): SegformerSelfOutput(\n",
              "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
              "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): SegformerMixFFN(\n",
              "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "              (dwconv): SegformerDWConv(\n",
              "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
              "              )\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): ModuleList(\n",
              "        (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
              "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decode_head): SegformerDecodeHead(\n",
              "    (linear_c): ModuleList(\n",
              "      (0): SegformerMLP(\n",
              "        (proj): Linear(in_features=32, out_features=256, bias=True)\n",
              "      )\n",
              "      (1): SegformerMLP(\n",
              "        (proj): Linear(in_features=64, out_features=256, bias=True)\n",
              "      )\n",
              "      (2): SegformerMLP(\n",
              "        (proj): Linear(in_features=160, out_features=256, bias=True)\n",
              "      )\n",
              "      (3): SegformerMLP(\n",
              "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (activation): ReLU()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# визуализируем и убедимся, что действительно выкинуты нужные слои\n",
        "student_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzLU9tZUwccp"
      },
      "source": [
        "## Train Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCyaw51Wwccq"
      },
      "source": [
        "Напишем старый-добрый трейнлуп и добавим в него дистилляционные лоссы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPahHGynwccq"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class TrainParams:\n",
        "    n_epochs: int\n",
        "    lr: float\n",
        "    batch_size: int\n",
        "    n_workers: int\n",
        "    device: torch.device\n",
        "\n",
        "    loss_weight: float\n",
        "    last_layer_loss_weight: float\n",
        "    intermediate_attn_layers_weights: tp.Tuple[float, float, float, float]\n",
        "    intermediate_feat_layers_weights: tp.Tuple[float, float, float, float]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFMkj8ODwccq"
      },
      "outputs": [],
      "source": [
        "train_params = TrainParams(\n",
        "    n_epochs=1,\n",
        "    lr=6e-5,\n",
        "    batch_size=16,\n",
        "    n_workers=8,\n",
        "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    loss_weight=0.5,\n",
        "    last_layer_loss_weight=0.5,\n",
        "    intermediate_attn_layers_weights=(0.5, 0.5, 0.5, 0.5),\n",
        "    intermediate_feat_layers_weights=(0.5, 0.5, 0.5, 0.5),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_T8ZKo0wccq"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    teacher_model,\n",
        "    student_model,\n",
        "    train_params: TrainParams,\n",
        "    student_teacher_attention_mapping,\n",
        "):\n",
        "    metric = load_metric('mean_iou')\n",
        "    teacher_model.to(train_params.device)\n",
        "    student_model.to(train_params.device)\n",
        "\n",
        "    teacher_model.eval()\n",
        "\n",
        "    train_dataloader, valid_dataloader = init_dataloaders(\n",
        "        root_dir=\".\",\n",
        "        batch_size=train_params.batch_size,\n",
        "        num_workers=train_params.n_workers,\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=train_params.lr)\n",
        "    step = 0\n",
        "    for epoch in range(train_params.n_epochs):\n",
        "        pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
        "        for idx, batch in pbar:\n",
        "            student_model.train()\n",
        "            # get the inputs;\n",
        "            pixel_values = batch['pixel_values'].to(train_params.device)\n",
        "            labels = batch['labels'].to(train_params.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            student_outputs = student_model(\n",
        "                pixel_values=pixel_values,\n",
        "                labels=labels,\n",
        "                output_attentions=True,\n",
        "                output_hidden_states=True,\n",
        "            )\n",
        "            loss, student_logits = student_outputs.loss, student_outputs.logits\n",
        "\n",
        "            # Чего это мы no_grad() при тренировке поставили?!\n",
        "            with torch.no_grad():\n",
        "                teacher_output = teacher_model(\n",
        "                    pixel_values=pixel_values,\n",
        "                    labels=labels,\n",
        "                    output_attentions=True,\n",
        "                    output_hidden_states=True,\n",
        "                )\n",
        "\n",
        "\n",
        "            last_layer_loss = calc_last_layer_loss(\n",
        "                student_logits,\n",
        "                teacher_output.logits,\n",
        "                train_params.last_layer_loss_weight,\n",
        "            )\n",
        "\n",
        "            student_attentions, teacher_attentions = student_outputs.attentions, teacher_output.attentions\n",
        "            student_hidden_states, teacher_hidden_states = student_outputs.hidden_states, teacher_output.hidden_states\n",
        "\n",
        "            intermediate_layer_att_loss = calc_intermediate_layers_attn_loss(\n",
        "                student_attentions,\n",
        "                teacher_attentions,\n",
        "                train_params.intermediate_attn_layers_weights,\n",
        "                student_teacher_attention_mapping,\n",
        "            )\n",
        "\n",
        "            intermediate_layer_feat_loss = calc_intermediate_layers_feat_loss(\n",
        "                student_hidden_states,\n",
        "                teacher_hidden_states,\n",
        "                train_params.intermediate_feat_layers_weights,\n",
        "            )\n",
        "\n",
        "            total_loss = loss* train_params.loss_weight + last_layer_loss\n",
        "            if intermediate_layer_att_loss is not None:\n",
        "                total_loss += intermediate_layer_att_loss\n",
        "\n",
        "            if intermediate_layer_feat_loss is not None:\n",
        "                total_loss += intermediate_layer_feat_loss\n",
        "\n",
        "            step += 1\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            pbar.set_description(f'total loss: {total_loss.item():.3f}')\n",
        "\n",
        "            for loss_value, loss_name in (\n",
        "                (loss, 'loss'),\n",
        "                (total_loss, 'total_loss'),\n",
        "                (last_layer_loss, 'last_layer_loss'),\n",
        "                (intermediate_layer_att_loss, 'intermediate_layer_att_loss'),\n",
        "                (intermediate_layer_feat_loss, 'intermediate_layer_feat_loss'),\n",
        "            ):\n",
        "                if loss_value is None: # для выключенной дистилляции атеншенов\n",
        "                    continue\n",
        "                tb_writer.add_scalar(\n",
        "                    tag=loss_name,\n",
        "                    scalar_value=loss_value.item(),\n",
        "                    global_step=step,\n",
        "                )\n",
        "\n",
        "        #после модификаций модели обязательно сохраняйте ее целиком, чтобы подгрузить ее в случае чего\n",
        "        torch.save(\n",
        "            {\n",
        "                'model': student_model,\n",
        "                'state_dict': student_model.state_dict(),\n",
        "                'optimizer_state': optimizer.state_dict(),\n",
        "            },\n",
        "            f'{save_dir}/ckpt_{epoch}.pth',\n",
        "        )\n",
        "\n",
        "        eval_metrics = evaluate_model(student_model, valid_dataloader, id2label)\n",
        "\n",
        "        for metric_key, metric_value in eval_metrics.items():\n",
        "            if not isinstance(metric_value, float):\n",
        "                continue\n",
        "            tb_writer.add_scalar(\n",
        "                tag=f'eval_{metric_key}',\n",
        "                scalar_value=metric_value,\n",
        "                global_step=epoch,\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDie9UHcwccr"
      },
      "source": [
        "### Лосс для дистилляции последних слоёв"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVI75JC8wccr"
      },
      "source": [
        "Напишем функцию `calc_last_layer_loss` , которая считает лосс между последними слоями учителя и ученика."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83JFI54qwccr"
      },
      "outputs": [],
      "source": [
        "mse_loss = nn.MSELoss()\n",
        "kl_loss = nn.KLDivLoss()\n",
        "\n",
        "def calc_last_layer_loss(student_logits, teacher_logits, weight):\n",
        "    \"\"\"Считаем лосс между выходами учителя и ученика\"\"\"\n",
        "    return mse_loss(student_logits, teacher_logits) * weight\n",
        "\n",
        "def calc_intermediate_layers_attn_loss(student_logits, teacher_logits, weights, student_teacher_attention_mapping):\n",
        "    return None\n",
        "\n",
        "def calc_intermediate_layers_feat_loss(student_feat, teacher_feat, weights):\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW9ZdkNPwccs"
      },
      "source": [
        "### Включим-посмотрим, как учится"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "uQ5x39HJdprN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm4etSB3wccs"
      },
      "outputs": [],
      "source": [
        "train(\n",
        "    teacher_model=teacher_model,\n",
        "    student_model=deepcopy(student_model),\n",
        "    train_params=train_params,\n",
        "    student_teacher_attention_mapping={}, # заполним потом\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDM1R4xuwccs"
      },
      "source": [
        "### Лосс для дистилляции атеншн-мап"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKbLlrVfwcct"
      },
      "source": [
        "Из каждого сегформер-блока можно достать атеншн-мапы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uHQCGo8wcct"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    teacher_attentions = teacher_model(pixel_values=torch.ones(1, 3, 512, 512).to(train_params.device), output_attentions=True).attentions\n",
        "    student_attentions = student_model(pixel_values=torch.ones(1, 3, 512, 512).to(train_params.device), output_attentions=True).attentions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YONDzVI2wcct",
        "outputId": "32a297c4-939b-4543-d8e7-24a2ae67d96a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 16384, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "teacher_attentions[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Два слоя учителя\")\n",
        "print(teacher_attentions[0].shape)\n",
        "print(teacher_attentions[1].shape)\n",
        "\n",
        "print(\"Против одного слоя ученика\")\n",
        "print(student_attentions[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U62jICobE2h9",
        "outputId": "27968328-e7c1-44df-b889-e14318f45c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Два слоя учителя\n",
            "torch.Size([1, 1, 16384, 256])\n",
            "torch.Size([1, 1, 16384, 256])\n",
            "Против одного слоя ученика\n",
            "torch.Size([1, 1, 16384, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_attentions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEGPRhIXhtI3",
        "outputId": "27b0c6ee-c23c-49e2-dc55-317baf1ef812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0034, 0.0025, 0.0025,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          [0.0026, 0.0022, 0.0022,  ..., 0.0040, 0.0040, 0.0040],\n",
              "          [0.0026, 0.0022, 0.0022,  ..., 0.0040, 0.0040, 0.0040],\n",
              "          ...,\n",
              "          [0.0038, 0.0023, 0.0023,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          [0.0038, 0.0023, 0.0023,  ..., 0.0039, 0.0039, 0.0039],\n",
              "          [0.0038, 0.0023, 0.0023,  ..., 0.0039, 0.0039, 0.0039]]]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ66hZ2gwcct"
      },
      "outputs": [],
      "source": [
        "assert len(teacher_attentions) == 8\n",
        "assert len(student_attentions) == 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GW9ue5zwcct"
      },
      "source": [
        "Будем дистиллировать и их!\n",
        "Но у учителя у нас их целых 8, а у ученика четыре. Поэтому нужно сделать соответствие: номер какой фичемапы у ученика\n",
        "будем тянуть к какому номеру фичемапы учителя."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCqjNM9Lwccu"
      },
      "outputs": [],
      "source": [
        "student_teacher_attention_mapping = {0: 1, 1: 3, 2: 5, 3: 7}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oc0XNDiwccv"
      },
      "source": [
        "Теперь напишем лосс, который принимает на вход списки фичемап ученика и учителя и тянет одно к другому."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r-ljdRwwccv"
      },
      "outputs": [],
      "source": [
        "def calc_intermediate_layers_loss(student_attentions, teacher_attentions, weights, student_teacher_attention_mapping):\n",
        "    intermediate_kl_loss = 0\n",
        "    for i, (stud_attn_idx, teach_attn_idx) in enumerate(student_teacher_attention_mapping.items()):\n",
        "        intermediate_kl_loss += weights[i] * kl_loss(\n",
        "            input=torch.log(student_attentions[stud_attn_idx]),\n",
        "            target=teacher_attentions[teach_attn_idx],\n",
        "        )\n",
        "    return intermediate_kl_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_intermediate_layers_attn_loss(student_attentions, teacher_attentions, (0.5, 0.5, 0.5, 0.5), student_teacher_attention_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbLodNL_IAFc",
        "outputId": "73c72af8-3b50-46eb-f4f9-a066b996fb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0420, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpTxRXoCLQ-L"
      },
      "source": [
        "### Лосс для дистилляции промежуточных фиче-мап"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9SEYAeBLQ-L"
      },
      "source": [
        "Помимо внимания, у вас также есть карты признаков, которые можно стягивать."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siaUkM-kLQ-L"
      },
      "outputs": [],
      "source": [
        "def calc_intermediate_layers_feat_loss(student_feats, teacher_feats, weights):\n",
        "    intermediate_mse_loss = 0.\n",
        "\n",
        "    for i in range(len(student_feats)):\n",
        "        intermediate_mse_loss += weights[i] * mse_loss(\n",
        "            input=student_feats[i],\n",
        "            target=teacher_feats[i],\n",
        "        )\n",
        "    return intermediate_mse_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifjr8NqXwccv"
      },
      "source": [
        "### Теперь можем тренировать со стягиванием разных фич"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = TrainParams(\n",
        "    n_epochs=1,\n",
        "    lr=6e-5,\n",
        "    batch_size=16,\n",
        "    n_workers=8,\n",
        "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    loss_weight=0.7,\n",
        "    last_layer_loss_weight=0.3,\n",
        "    intermediate_attn_layers_weights=(0.5, 0.5, 0.5, 0.5),\n",
        "    intermediate_feat_layers_weights=(0.5, 0.5, 0.5, 0.5),\n",
        ")"
      ],
      "metadata": {
        "id": "bO5AJ-0ObGgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ARtDhqcsMxrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nammE-JCwccv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "1ed7760853de49ffa7d3b6454c9444fa",
            "11d3ba4e306c4a2897792c509082d6b4",
            "d6d5f3e44f42426cba226a1d185add6f",
            "00a26fe0f27448e896fa2071e390339a",
            "aa4afb8c8e4544f7ad7711613960d341",
            "ddb47dc7bd5d4f469952c7125b644695",
            "c08deaba09fc44a7ac7d4ded1b2e6567",
            "ff1ff1d5450e4d19911918ae28e1be92",
            "d830c75649fc4a039752cc7d66ff4b33",
            "fe6668c09962491cb1a4d848cae1a303",
            "faa4fa15e3b149a39d67b64932814c2b"
          ]
        },
        "outputId": "851e8b57-e63c-4031-9b7d-247f9108e753"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ed7760853de49ffa7d3b6454c9444fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1129 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:3369: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train(\n",
        "    teacher_model=teacher_model,\n",
        "    student_model=deepcopy(student_model),\n",
        "    train_params=train_params,\n",
        "    student_teacher_attention_mapping=student_teacher_attention_mapping,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ed7760853de49ffa7d3b6454c9444fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11d3ba4e306c4a2897792c509082d6b4",
              "IPY_MODEL_d6d5f3e44f42426cba226a1d185add6f",
              "IPY_MODEL_00a26fe0f27448e896fa2071e390339a"
            ],
            "layout": "IPY_MODEL_aa4afb8c8e4544f7ad7711613960d341"
          }
        },
        "11d3ba4e306c4a2897792c509082d6b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddb47dc7bd5d4f469952c7125b644695",
            "placeholder": "​",
            "style": "IPY_MODEL_c08deaba09fc44a7ac7d4ded1b2e6567",
            "value": "total loss: 1.774: 100%"
          }
        },
        "d6d5f3e44f42426cba226a1d185add6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff1ff1d5450e4d19911918ae28e1be92",
            "max": 1129,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d830c75649fc4a039752cc7d66ff4b33",
            "value": 1129
          }
        },
        "00a26fe0f27448e896fa2071e390339a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe6668c09962491cb1a4d848cae1a303",
            "placeholder": "​",
            "style": "IPY_MODEL_faa4fa15e3b149a39d67b64932814c2b",
            "value": " 1129/1129 [1:01:52&lt;00:00,  2.34s/it]"
          }
        },
        "aa4afb8c8e4544f7ad7711613960d341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb47dc7bd5d4f469952c7125b644695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c08deaba09fc44a7ac7d4ded1b2e6567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff1ff1d5450e4d19911918ae28e1be92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d830c75649fc4a039752cc7d66ff4b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe6668c09962491cb1a4d848cae1a303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa4fa15e3b149a39d67b64932814c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}